{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df953aa",
   "metadata": {},
   "source": [
    "# Support Vector Machine [SVM] - Classification:\n",
    "\n",
    "**Usage**: classification & regression both [supervised].\n",
    "\n",
    "**Goal**: Finding the best decision boundary (hyperplane) separating the classes with maximum margin.\n",
    "\n",
    "- **Hyperplane**: Decision boundary - separating classes with max margin. \n",
    "    - Equation: $w^T\\cdot x+b = 0$\n",
    "\n",
    "- **Support Vectors**: Closest data points to hyperplane. [crucial in determining the hyperplane & margin in SVM].\n",
    "\n",
    "- **Margin**: Distance between hyperplane & support vectors. SVM aims to maximize the margin to improve performance.\n",
    "\n",
    "- **Kernel**: Function to map the data to a higher-dimensional space enabling SVM to handle non-linearly separable data.\n",
    "\n",
    "- **Hard Margin**: max-margin in hyperplane that perfectly separates the data. [no misclassifications]\n",
    "\n",
    "- **Soft Margin**: allows some missclassifications when data is not perfectly separable.\n",
    "\n",
    "- **C**: regularization term balancing margin maximization & missclass. penalties. $\\uparrow C \\propto$ *stricter penalties*.\n",
    "\n",
    "- **Hinge Loss**: loss function.\n",
    "\n",
    "\n",
    "## SVM Functionality:\n",
    "\n",
    "- Hyperplane:\n",
    "\n",
    "    $w^T \\cdot x + b = 0$\n",
    "    - $w$: weight (normal to hyperplane)\n",
    "    - $b$: bias (shifting the plane)\n",
    "    - $x$: features (inputs)\n",
    "\n",
    "- To predict / margin-region:\n",
    "    \n",
    "    $y^{(k)} =\n",
    "    \\begin{cases}\n",
    "    +1 & \\text{if } \\mathbf{w}^T \\mathbf{x} + b \\geq 0 \\\\\n",
    "    -1 & \\text{if } \\mathbf{w}^T \\mathbf{x} + b < 0\n",
    "    \\end{cases}\n",
    "    $\n",
    "\n",
    "**Optimization**:\n",
    "\n",
    "$||\\text{w}|| = \\sqrt{w_1^2 + w_2^2 + ... + w_n^2}$\n",
    "\n",
    "> where, $||\\text{w}||$ - Norm of Vector (Euclidean norm)\n",
    "\n",
    "1. $\\text{Margin} = \\frac{2}{||\\text{w}||}$\n",
    "\n",
    "2. $\\text{Hard-Margin} = \\min_{w,b} \\frac{1}{2} {||\\text{w}||^2}$, \n",
    "    - subject to: $y_i(w^T \\cdot x_i + b) \\geq 1$\n",
    "    - No missclassifications allowed \n",
    "\n",
    "3. $\\text{soft-margin} = \\min_{w,b,\\xi} \\frac{1}{2}{||\\text{w}||^2} + C\\cdot \\sum_{i=1}^{n}{\\xi_i}$\n",
    "\n",
    "    - subject to: $y_i(w^T \\cdot x_i + b) \\geq 1 - \\xi_i, \\xi \\geq 0$  \n",
    "    - allows some missclassifications.\n",
    "    - $\\xi_i$ refers to the penalty (slack).\n",
    "\n",
    "4. Hinge Loss:\n",
    "\n",
    "    $f(x) = w^T \\cdot x_i + b$\n",
    "\n",
    "    $L(y, f(x)) = max(0, 1 - y_i\\cdot f(x))$\n",
    "\n",
    "\n",
    "Optimization Objective:\n",
    "\n",
    "- $(\\text{maximize margin}) + C \\cdot L(y, f(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6c1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go \n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23454487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
